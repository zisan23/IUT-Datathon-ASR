{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9bbea9",
   "metadata": {
    "papermill": {
     "duration": 0.003304,
     "end_time": "2023-10-19T06:25:38.095998",
     "exception": false,
     "start_time": "2023-10-19T06:25:38.092694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2839519b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-10-19T06:25:38.102876Z",
     "iopub.status.busy": "2023-10-19T06:25:38.102622Z",
     "iopub.status.idle": "2023-10-19T06:27:01.281690Z",
     "shell.execute_reply": "2023-10-19T06:27:01.280768Z"
    },
    "papermill": {
     "duration": 83.184698,
     "end_time": "2023-10-19T06:27:01.283741",
     "exception": false,
     "start_time": "2023-10-19T06:25:38.099043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jiwer/\r\n",
      "jiwer/jiwer-2.3.0-py3-none-any.whl\r\n",
      "jiwer/python-Levenshtein-0.12.2.tar.gz\r\n",
      "jiwer/setuptools-65.3.0-py3-none-any.whl\r\n",
      "Looking in links: ./\r\n",
      "Processing ./jiwer/jiwer-2.3.0-py3-none-any.whl\r\n",
      "INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\r\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-Levenshtein==0.12.2 (from jiwer) (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for python-Levenshtein==0.12.2\u001b[0m\u001b[31m\r\n",
      "\u001b[0mnormalizer/\r\n",
      "normalizer/bnunicodenormalizer-0.0.24.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./normalizer/bnunicodenormalizer-0.0.24.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: bnunicodenormalizer\r\n",
      "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.0.24-py3-none-any.whl size=17628 sha256=34e0ca1d54a5895c72a046e250e10068089a38b1f23a525b162f939a6f7b99f8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/d7/75/6986dc3616718f950b80e3bd79a796ef618eaef6cd800e7909\r\n",
      "Successfully built bnunicodenormalizer\r\n",
      "Installing collected packages: bnunicodenormalizer\r\n",
      "Successfully installed bnunicodenormalizer-0.0.24\r\n",
      "pyctcdecode/\r\n",
      "pyctcdecode/hypothesis-6.54.4-py3-none-any.whl\r\n",
      "pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\r\n",
      "pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\r\n",
      "pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\r\n",
      "pyctcdecode/pygtrie-2.5.0.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: attrs\r\n",
      "  Attempting uninstall: attrs\r\n",
      "    Found existing installation: attrs 23.1.0\r\n",
      "    Uninstalling attrs-23.1.0:\r\n",
      "      Successfully uninstalled attrs-23.1.0\r\n",
      "Successfully installed attrs-22.1.0\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl\r\n",
      "Installing collected packages: exceptiongroup\r\n",
      "  Attempting uninstall: exceptiongroup\r\n",
      "    Found existing installation: exceptiongroup 1.1.1\r\n",
      "    Uninstalling exceptiongroup-1.1.1:\r\n",
      "      Successfully uninstalled exceptiongroup-1.1.1\r\n",
      "Successfully installed exceptiongroup-1.0.0rc9\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl\r\n",
      "Installing collected packages: hypothesis\r\n",
      "Successfully installed hypothesis-6.54.4\r\n",
      "Looking in links: ./\r\n",
      "\u001b[31mERROR: numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mLooking in links: ./\r\n",
      "Processing ./pyctcdecode/pygtrie-2.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pygtrie\r\n",
      "  Building wheel for pygtrie (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pygtrie: filename=pygtrie-2.5.0-py3-none-any.whl size=20945 sha256=3e49677b92764abfbcf57fb28703ceb3ac1bd791df6d744b20d090f724d94e6b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/28/09/b62c97a3e77102645c7ecc78c97580ad57090b1eee5438d6ac\r\n",
      "Successfully built pygtrie\r\n",
      "Installing collected packages: pygtrie\r\n",
      "Successfully installed pygtrie-2.5.0\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl\r\n",
      "sortedcontainers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: pyctcdecode\r\n",
      "Successfully installed pyctcdecode-0.4.0\r\n",
      "pypikenlm/\r\n",
      "pypikenlm/pypi-kenlm-0.1.20220713.tar.gz\r\n",
      "Looking in links: ./\r\n",
      "Processing ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypi-kenlm\r\n",
      "  Building wheel for pypi-kenlm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pypi-kenlm: filename=pypi_kenlm-0.1.20220713-cp310-cp310-linux_x86_64.whl size=333264 sha256=7fd53556fa0c7d1e4729a2d78935822a381e5eb08d80b5b21af09871a5e39bfc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/7a/db/27645fac296d5d5ba5c461b1af834eebc0ba4643290dbc5476\r\n",
      "Successfully built pypi-kenlm\r\n",
      "Installing collected packages: pypi-kenlm\r\n",
      "Successfully installed pypi-kenlm-0.1.20220713\r\n",
      "Looking in links: ../input/bengaliai-pip-wheels-demucs\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/demucs-4.0.1.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/bengaliai-pip-wheels-demucs/dora_search-0.1.12.tar.gz (from demucs)\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/bengaliai-pip-wheels-demucs/einops-0.6.1-py3-none-any.whl (from demucs)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/julius-0.2.7.tar.gz (from demucs)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hProcessing /kaggle/input/bengaliai-pip-wheels-demucs/lameenc-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (from demucs)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/openunmix-1.2.1-py3-none-any.whl (from demucs)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from demucs) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from demucs) (2.0.0)\r\n",
      "Requirement already satisfied: torchaudio>=0.8 in /opt/conda/lib/python3.10/site-packages (from demucs) (2.0.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from demucs) (4.65.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->demucs) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->demucs) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->demucs) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->demucs) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->demucs) (3.1.2)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/omegaconf-2.3.0-py3-none-any.whl (from dora-search->demucs)\r\n",
      "Requirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from dora-search->demucs) (1.3.3)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/submitit-1.4.6-py3-none-any.whl (from dora-search->demucs)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/treetable-0.2.5.tar.gz (from dora-search->demucs)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openunmix->demucs) (1.23.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->demucs) (2.1.3)\r\n",
      "Processing /kaggle/input/bengaliai-pip-wheels-demucs/antlr4-python3-runtime-4.9.3.tar.gz (from omegaconf->dora-search->demucs)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from retrying->dora-search->demucs) (1.16.0)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from submitit->dora-search->demucs) (2.2.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->demucs) (1.3.0)\r\n",
      "Building wheels for collected packages: demucs, julius, dora-search, antlr4-python3-runtime, treetable\r\n",
      "  Building wheel for demucs (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for demucs: filename=demucs-4.0.1-py3-none-any.whl size=78414 sha256=bd308408218b06b9b85d407a6c7ebf7abcc4b960d45c2ce34632f4647573efcf\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/7d/02/a0c5b191e23c8931a0050a67577dc78bd6ab3203aceb15541b\r\n",
      "  Building wheel for julius (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21895 sha256=b64316bdecc56e209680d06fd45aab689a792b6a6a278bda6b482a0d19a42fbb\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/e5/56/e5d5f09ca103b9a7a492f3f6da94f50170bb9831936680b3c5\r\n",
      "  Building wheel for dora-search (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for dora-search: filename=dora_search-0.1.12-py3-none-any.whl size=75090 sha256=8be5ecddf56d76eeca0cbe47801dcc6c6e3d02928a334faee6f11f36e2722426\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/66/6b/b3918d656f4343c6231e75c289bb5bb0e29311e5dbf23289a8\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144574 sha256=8f25a8ae22754c59a204e6804c74dab3c086eeff2ec813a9f46fe5e5e755940c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/06/af/b7/82674fa93fbf0c467bda826df6b0c363f7787fef943d400c56\r\n",
      "  Building wheel for treetable (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for treetable: filename=treetable-0.2.5-py3-none-any.whl size=7350 sha256=270682e21ceeb0d6ea8ef68fe60ae9e3f8d6e29ce9f5d1246cf3d50ee5fece7c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/7a/6b/367f97297db4367e2040440cf494d84d901a6d143e5dd0e3e5\r\n",
      "Successfully built demucs julius dora-search antlr4-python3-runtime treetable\r\n",
      "Installing collected packages: lameenc, antlr4-python3-runtime, treetable, submitit, omegaconf, einops, julius, dora-search, openunmix, demucs\r\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 demucs-4.0.1 dora-search-0.1.12 einops-0.6.1 julius-0.2.7 lameenc-1.6.1 omegaconf-2.3.0 openunmix-1.2.1 submitit-1.4.6 treetable-0.2.5\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r ../input/python-packages2 ./\n",
    "\n",
    "!tar xvfz ./python-packages2/jiwer.tgz\n",
    "!pip install ./jiwer/jiwer-2.3.0-py3-none-any.whl -f ./ --no-index\n",
    "!tar xvfz ./python-packages2/normalizer.tgz\n",
    "!pip install ./normalizer/bnunicodenormalizer-0.0.24.tar.gz -f ./ --no-index\n",
    "!tar xvfz ./python-packages2/pyctcdecode.tgz\n",
    "!pip install ./pyctcdecode/attrs-22.1.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/exceptiongroup-1.0.0rc9-py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/hypothesis-6.54.4-py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/pygtrie-2.5.0.tar.gz -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/sortedcontainers-2.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "!pip install ./pyctcdecode/pyctcdecode-0.4.0-py2.py3-none-any.whl -f ./ --no-index --no-deps\n",
    "\n",
    "!tar xvfz ./python-packages2/pypikenlm.tgz\n",
    "!pip install ./pypikenlm/pypi-kenlm-0.1.20220713.tar.gz -f ./ --no-index --no-deps\n",
    "\n",
    "import os\n",
    "!python -m pip install --no-index --find-links=../input/bengaliai-pip-wheels-demucs demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e96d7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:27:01.301651Z",
     "iopub.status.busy": "2023-10-19T06:27:01.301350Z",
     "iopub.status.idle": "2023-10-19T06:27:02.263666Z",
     "shell.execute_reply": "2023-10-19T06:27:02.262654Z"
    },
    "papermill": {
     "duration": 0.974083,
     "end_time": "2023-10-19T06:27:02.266239",
     "exception": false,
     "start_time": "2023-10-19T06:27:01.292156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -r python-packages2 jiwer normalizer pyctcdecode pypikenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8dfa35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:27:02.283971Z",
     "iopub.status.busy": "2023-10-19T06:27:02.283696Z",
     "iopub.status.idle": "2023-10-19T06:27:03.223596Z",
     "shell.execute_reply": "2023-10-19T06:27:03.222519Z"
    },
    "papermill": {
     "duration": 0.950787,
     "end_time": "2023-10-19T06:27:03.225397",
     "exception": false,
     "start_time": "2023-10-19T06:27:02.274610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ./generated_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc888ad4",
   "metadata": {
    "papermill": {
     "duration": 0.007808,
     "end_time": "2023-10-19T06:27:03.241661",
     "exception": false,
     "start_time": "2023-10-19T06:27:03.233853",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df6fdd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:27:03.258911Z",
     "iopub.status.busy": "2023-10-19T06:27:03.258640Z",
     "iopub.status.idle": "2023-10-19T06:27:41.453225Z",
     "shell.execute_reply": "2023-10-19T06:27:41.452482Z"
    },
    "papermill": {
     "duration": 38.205725,
     "end_time": "2023-10-19T06:27:41.455147",
     "exception": false,
     "start_time": "2023-10-19T06:27:03.249422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to separate the files:\n",
      "/kaggle/input/bengaliai-speech/test_mp3s/a9395e01ad21.mp3\n",
      "/kaggle/input/bengaliai-speech/test_mp3s/0f3dac00655e.mp3\n",
      "/kaggle/input/bengaliai-speech/test_mp3s/bf36ea8b718d.mp3\n",
      "With command:  python3 -m demucs.separate -o ./music_output -n htdemucs --repo /kaggle/input/demucs-model --mp3 --mp3-bitrate=48000 --two-stems=vocals\n",
      "Separated tracks will be stored in /kaggle/working/music_output/htdemucs\n",
      "Separating track /kaggle/input/bengaliai-speech/test_mp3s/a9395e01ad21.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11.7/11.7 [00:05<00:00,  2.32seconds/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating track /kaggle/input/bengaliai-speech/test_mp3s/0f3dac00655e.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:00<00:00, 34.22seconds/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating track /kaggle/input/bengaliai-speech/test_mp3s/bf36ea8b718d.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:00<00:00, 34.29seconds/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import glob\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = DATA / \"test_mp3s\"\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-sr-download-public-trained-models/indicwav2vec_v1_bengali/\"\n",
    "LM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\"\n",
    "\n",
    "# Customize the following options!\n",
    "model = \"htdemucs\"\n",
    "extensions = [\"mp3\", \"wav\", \"ogg\", \"flac\"]  # we will look for all those file types.\n",
    "# two_stems = None   # only separate one stems from the rest, for instance\n",
    "two_stems = \"vocals\"\n",
    "\n",
    "# Options for the output audio.\n",
    "mp3 = True\n",
    "mp3_rate = 48000\n",
    "float32 = False  # output as float 32 wavs, unsused if 'mp3' is True.\n",
    "int24 = False    # output as int24 wavs, unused if 'mp3' is True.\n",
    "# You cannot set both `float32 = True` and `int24 = True` !!\n",
    "\n",
    "in_path = TEST\n",
    "out_path = './music_output'\n",
    "repo_path = '/kaggle/input/demucs-model'\n",
    "\n",
    "#@title Useful functions, don't forget to execute\n",
    "import io\n",
    "from pathlib import Path\n",
    "import select\n",
    "from shutil import rmtree\n",
    "import subprocess as sp\n",
    "import sys\n",
    "from typing import Dict, Tuple, Optional, IO\n",
    "\n",
    "def find_files(in_path):\n",
    "    out = []\n",
    "    for file in Path(in_path).iterdir():\n",
    "        if file.suffix.lower().lstrip(\".\") in extensions:\n",
    "            out.append(file)\n",
    "    return out\n",
    "\n",
    "def copy_process_streams(process: sp.Popen):\n",
    "    def raw(stream: Optional[IO[bytes]]) -> IO[bytes]:\n",
    "        assert stream is not None\n",
    "        if isinstance(stream, io.BufferedIOBase):\n",
    "            stream = stream.raw\n",
    "        return stream\n",
    "\n",
    "    p_stdout, p_stderr = raw(process.stdout), raw(process.stderr)\n",
    "    stream_by_fd: Dict[int, Tuple[IO[bytes], io.StringIO, IO[str]]] = {\n",
    "        p_stdout.fileno(): (p_stdout, sys.stdout),\n",
    "        p_stderr.fileno(): (p_stderr, sys.stderr),\n",
    "    }\n",
    "    fds = list(stream_by_fd.keys())\n",
    "\n",
    "    while fds:\n",
    "        # `select` syscall will wait until one of the file descriptors has content.\n",
    "        ready, _, _ = select.select(fds, [], [])\n",
    "        for fd in ready:\n",
    "            p_stream, std = stream_by_fd[fd]\n",
    "            raw_buf = p_stream.read(2 ** 16)\n",
    "            if not raw_buf:\n",
    "                fds.remove(fd)\n",
    "                continue\n",
    "            buf = raw_buf.decode()\n",
    "            std.write(buf)\n",
    "            std.flush()\n",
    "\n",
    "def separate(inp=None, outp=None):\n",
    "    inp = inp or in_path\n",
    "    outp = outp or out_path\n",
    "    cmd = [\"python3\", \"-m\", \"demucs.separate\", \"-o\", str(outp), \"-n\", model, \"--repo\", repo_path]\n",
    "    if mp3:\n",
    "        cmd += [\"--mp3\", f\"--mp3-bitrate={mp3_rate}\"]\n",
    "    if float32:\n",
    "        cmd += [\"--float32\"]\n",
    "    if int24:\n",
    "        cmd += [\"--int24\"]\n",
    "    if two_stems is not None:\n",
    "        cmd += [f\"--two-stems={two_stems}\"]\n",
    "    files = [str(f) for f in find_files(inp)]\n",
    "    if not files:\n",
    "        print(f\"No valid audio files in {in_path}\")\n",
    "        return\n",
    "    print(\"Going to separate the files:\")\n",
    "    print('\\n'.join(files))\n",
    "    print(\"With command: \", \" \".join(cmd))\n",
    "    p = sp.Popen(cmd + files, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    copy_process_streams(p)\n",
    "    p.wait()\n",
    "    if p.returncode != 0:\n",
    "        print(\"Command failed, something went wrong.\")\n",
    "\n",
    "separate()\n",
    "\n",
    "dirlist = glob.glob(f'./{out_path}/htdemucs/*/')\n",
    "for d in dirlist:\n",
    "    before = os.path.join(d, 'vocals.mp3')\n",
    "    after = os.path.join('./generated_audio', d[:-1].replace(f'./{out_path}/htdemucs/', '')+'.mp3')\n",
    "    subprocess.run(f\"mv {before} {after}\",\n",
    "                   shell=True, capture_output=True, text=True)\n",
    "\n",
    "TEST = Path('./generated_audio')\n",
    "\n",
    "# import soundfile as sf\n",
    "for d in glob.glob(str(TEST/'*')):\n",
    "    audio = librosa.load(d, sr=16000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777c157",
   "metadata": {
    "papermill": {
     "duration": 0.008524,
     "end_time": "2023-10-19T06:27:41.473316",
     "exception": false,
     "start_time": "2023-10-19T06:27:41.464792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7607ec52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:27:41.491980Z",
     "iopub.status.busy": "2023-10-19T06:27:41.491716Z",
     "iopub.status.idle": "2023-10-19T06:34:15.836333Z",
     "shell.execute_reply": "2023-10-19T06:34:15.835310Z"
    },
    "papermill": {
     "duration": 394.356666,
     "end_time": "2023-10-19T06:34:15.838568",
     "exception": false,
     "start_time": "2023-10-19T06:27:41.481902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = DATA / \"test_mp3s\"\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-sr-download-public-trained-models/indicwav2vec_v1_bengali/\"\n",
    "LM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\"\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/baisr-ver5-3/model_ver5_3_WER0.32805.pth', map_location=device)['model'])\n",
    "\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    str(\"/kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\"),\n",
    ")\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr)[0]\n",
    "\n",
    "        return w\n",
    "\n",
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "test['original_index'] = test.index\n",
    "test['path'] = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "def read_audio(mp3_path, target_sr=16000):\n",
    "    audio, sr = librosa.load(mp3_path, sr=32000)\n",
    "    return audio\n",
    "\n",
    "def get_audio_length(row):\n",
    "    audio = read_audio(row['path'])\n",
    "    row['audio_length'] = len(audio)/32000 \n",
    "    return row\n",
    "\n",
    "test = test.apply(get_audio_length, axis=1)\n",
    "\n",
    "test = test.sort_values('audio_length').reset_index(drop=True)\n",
    "\n",
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "model = model.half()\n",
    "\n",
    "pred_sentence_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        for l in y:  \n",
    "            sentence = processor_with_lm.decode(l, beam_width=10).text\n",
    "            pred_sentence_list.append(sentence)\n",
    "\n",
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        sentence = \" \".join(re.sub('[\\,\\।\\?\\!\\-]', \" \", sentence).split())\n",
    "        if len(sentence) == 0:\n",
    "            sentence = \"।\"\n",
    "    except:\n",
    "        sentence = \"।\"\n",
    "    return sentence\n",
    "\n",
    "pp_pred_sentence_list = [\n",
    "    postprocess(s) for s in tqdm(pred_sentence_list)]\n",
    "\n",
    "test[\"sentence\"] = pp_pred_sentence_list\n",
    "test = test.sort_values('original_index').reset_index(drop=True).drop(['original_index', 'audio_length', 'path'], axis=1)\n",
    "test.to_csv(\"pre_submission_no_demucs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924ad2b1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-19T06:34:15.859528Z",
     "iopub.status.busy": "2023-10-19T06:34:15.859266Z",
     "iopub.status.idle": "2023-10-19T06:38:04.141733Z",
     "shell.execute_reply": "2023-10-19T06:38:04.140809Z"
    },
    "papermill": {
     "duration": 228.295156,
     "end_time": "2023-10-19T06:38:04.143856",
     "exception": false,
     "start_time": "2023-10-19T06:34:15.848700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = Path('./generated_audio')\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-sr-download-public-trained-models/indicwav2vec_v1_bengali/\"\n",
    "LM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\"\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/baisr-ver5-3/model_ver5_3_WER0.32805.pth', map_location=device)['model'])\n",
    "\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    str(\"/kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\"),\n",
    ")\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr)[0]\n",
    "\n",
    "        return w\n",
    "\n",
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "test['original_index'] = test.index\n",
    "test['path'] = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "def read_audio(mp3_path, target_sr=16000):\n",
    "    audio, sr = librosa.load(mp3_path, sr=32000)\n",
    "    return audio\n",
    "\n",
    "def get_audio_length(row):\n",
    "    audio = read_audio(row['path'])\n",
    "    row['audio_length'] = len(audio)/32000 \n",
    "    return row\n",
    "\n",
    "test = test.apply(get_audio_length, axis=1)\n",
    "\n",
    "test = test.sort_values('audio_length').reset_index(drop=True)\n",
    "\n",
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "model = model.half()\n",
    "\n",
    "pred_sentence_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        for l in y:  \n",
    "            sentence = processor_with_lm.decode(l, beam_width=10).text\n",
    "            pred_sentence_list.append(sentence)\n",
    "\n",
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        sentence = \" \".join(re.sub('[\\,\\।\\?\\!\\-]', \" \", sentence).split())\n",
    "        if len(sentence) == 0:\n",
    "            sentence = \"।\"\n",
    "    except:\n",
    "        sentence = \"।\"\n",
    "    return sentence\n",
    "\n",
    "pp_pred_sentence_list = [\n",
    "    postprocess(s) for s in tqdm(pred_sentence_list)]\n",
    "\n",
    "test[\"sentence\"] = pp_pred_sentence_list\n",
    "test = test.sort_values('original_index').reset_index(drop=True).drop(['original_index', 'audio_length', 'path'], axis=1)\n",
    "test.to_csv(\"pre_submission_demucs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19367515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:38:04.165720Z",
     "iopub.status.busy": "2023-10-19T06:38:04.165395Z",
     "iopub.status.idle": "2023-10-19T06:38:04.728319Z",
     "shell.execute_reply": "2023-10-19T06:38:04.727627Z"
    },
    "papermill": {
     "duration": 0.576062,
     "end_time": "2023-10-19T06:38:04.730624",
     "exception": false,
     "start_time": "2023-10-19T06:38:04.154562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "df_before = pd.read_csv('pre_submission_no_demucs.csv')\n",
    "df_after = pd.read_csv('pre_submission_demucs.csv')\n",
    "pred = []\n",
    "for id, before, after in zip(df_after[\"id\"].values, df_before[\"sentence\"].values, df_after[\"sentence\"].values):\n",
    "    if len(after.split()) < len(before.split()):\n",
    "        subprocess.run(f'cp /kaggle/input/bengaliai-speech/test_mp3s/{id}.mp3 ./generated_audio/{id}.mp3', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978bbcd",
   "metadata": {
    "papermill": {
     "duration": 0.0099,
     "end_time": "2023-10-19T06:38:04.751072",
     "exception": false,
     "start_time": "2023-10-19T06:38:04.741172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed2836c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:38:04.772074Z",
     "iopub.status.busy": "2023-10-19T06:38:04.771824Z",
     "iopub.status.idle": "2023-10-19T06:41:54.111504Z",
     "shell.execute_reply": "2023-10-19T06:41:54.110761Z"
    },
    "papermill": {
     "duration": 229.352591,
     "end_time": "2023-10-19T06:41:54.113502",
     "exception": false,
     "start_time": "2023-10-19T06:38:04.760911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pyctcdecode\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import librosa\n",
    "\n",
    "import pyctcdecode\n",
    "import kenlm\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC\n",
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "import cloudpickle as cpkl\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "DATA = INPUT / \"bengaliai-speech\"\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = Path('./generated_audio')\n",
    "\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = INPUT / \"bengali-sr-download-public-trained-models/indicwav2vec_v1_bengali/\"\n",
    "LM_PATH = INPUT / \"bengali-sr-download-public-trained-models/wav2vec2-xls-r-300m-bengali/language_model/\"\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/input/baisr-ver5-3/model_ver5_3_WER0.32805.pth', map_location=device)['model'])\n",
    "\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    str(\"/kaggle/input/5gramlm4/5gram_normalized_bn_train_commonvoice_fleurs_openslr_openslr37_oscar_without_punc_prune2.arpa\"),\n",
    ")\n",
    "\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    decoder=decoder\n",
    ")\n",
    "\n",
    "class BengaliSRTestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths: list[str],\n",
    "        sampling_rate: int\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.sampling_rate = sampling_rate\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        audio_path = self.audio_paths[index]\n",
    "        sr = self.sampling_rate\n",
    "        w = librosa.load(audio_path, sr=sr)[0]\n",
    "\n",
    "        return w\n",
    "\n",
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "test['original_index'] = test.index\n",
    "test['path'] = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "def read_audio(mp3_path, target_sr=16000):\n",
    "    audio, sr = librosa.load(mp3_path, sr=32000)\n",
    "    return audio\n",
    "\n",
    "def get_audio_length(row):\n",
    "    audio = read_audio(row['path'])\n",
    "    row['audio_length'] = len(audio)/32000 \n",
    "    return row\n",
    "\n",
    "test = test.apply(get_audio_length, axis=1)\n",
    "\n",
    "test = test.sort_values('audio_length').reset_index(drop=True)\n",
    "\n",
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]\n",
    "\n",
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=8, shuffle=False,\n",
    "    num_workers=2, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "model = model.half()\n",
    "\n",
    "pred_sentence_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        for l in y:  \n",
    "            sentence = processor_with_lm.decode(l, beam_width=256*3).text\n",
    "            pred_sentence_list.append(sentence)\n",
    "\n",
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        sentence = \" \".join(re.sub('[\\,\\।\\?\\!\\-]', \" \", sentence).split())\n",
    "        if len(sentence) == 0:\n",
    "            sentence = \"।\"\n",
    "    except:\n",
    "        sentence = \"।\"\n",
    "    return sentence\n",
    "\n",
    "pp_pred_sentence_list = [\n",
    "    postprocess(s) for s in tqdm(pred_sentence_list)]\n",
    "\n",
    "test[\"sentence\"] = pp_pred_sentence_list\n",
    "test = test.sort_values('original_index').reset_index(drop=True).drop(['original_index', 'audio_length', 'path'], axis=1)\n",
    "test.to_csv(\"pre_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de05e9f",
   "metadata": {
    "papermill": {
     "duration": 0.013151,
     "end_time": "2023-10-19T06:41:54.138973",
     "exception": false,
     "start_time": "2023-10-19T06:41:54.125822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb62846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:41:54.163176Z",
     "iopub.status.busy": "2023-10-19T06:41:54.162918Z",
     "iopub.status.idle": "2023-10-19T06:44:13.385765Z",
     "shell.execute_reply": "2023-10-19T06:44:13.384808Z"
    },
    "papermill": {
     "duration": 139.237427,
     "end_time": "2023-10-19T06:44:13.387857",
     "exception": false,
     "start_time": "2023-10-19T06:41:54.150430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/vakyansh-models-punctuation-models-bengali\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/indic_nlp_library-0.92-py3-none-any.whl\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinx_argparse-0.4.0-py3-none-any.whl (from indic-nlp-library)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (0.2.4)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/Morfessor-2.0.6-py3-none-any.whl (from indic-nlp-library)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (1.5.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library) (2023.3)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinx-7.2.6-py3-none-any.whl (from sphinx-argparse->indic-nlp-library)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library) (1.16.0)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\n",
      "Requirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.1)\n",
      "Requirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.20.1)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/alabaster-0.7.13-py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Processing /kaggle/input/vakyansh-models-punctuation-models-bengali/imagesize-1.4.1-py2.py3-none-any.whl (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library)\n",
      "Requirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2023.5.7)\n",
      "Installing collected packages: morfessor, sphinxcontrib-jsmath, imagesize, alabaster, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, sphinx-argparse, indic-nlp-library\n",
      "Successfully installed alabaster-0.7.13 imagesize-1.4.1 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-7.2.6 sphinx-argparse-0.4.0 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Some weights of the model checkpoint at /kaggle/input/xlm-roberta-large were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /kaggle/input/xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at /kaggle/input/bengaliai-xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at /kaggle/input/bengaliai-xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system('python -m pip install --no-index --find-links=../input/vakyansh-models-punctuation-models-bengali indic-nlp-library')\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "\n",
    "CHECKPOINT_PATH = '/kaggle/input/punctuation-models/xlm-roberta-large_exp016_cp175.pt'\n",
    "LABEL_ENCODER_PATH = '/kaggle/input/punctuation-models/label_encoder.json'\n",
    "\n",
    "label_encoder_path = LABEL_ENCODER_PATH\n",
    "punctuation_dict = {'qm': '? ', 'comma': ', ', 'end': '। ', 'blank': ' ', 'hyp': '-', 'PAD': ' '}\n",
    "\n",
    "with open(label_encoder_path) as label_encoder:\n",
    "    train_encoder = json.load(label_encoder)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/kaggle/input/xlm-roberta-large',\n",
    ")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    '/kaggle/input/xlm-roberta-large',\n",
    "    num_labels=len(train_encoder),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "# Added model\n",
    "CHECKPOINT_PATH_1 = '/kaggle/input/punctuation-models/xlm-roberta-base_exp017_cp200.pt'\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(\n",
    "    '/kaggle/input/bengaliai-xlm-roberta-base',\n",
    ")\n",
    "model_1 = AutoModelForTokenClassification.from_pretrained(\n",
    "    '/kaggle/input/bengaliai-xlm-roberta-base',\n",
    "    num_labels=len(train_encoder),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "checkpoint_1 = torch.load(CHECKPOINT_PATH_1)\n",
    "model_1.load_state_dict(checkpoint_1['state_dict'], strict=False)\n",
    "model_1.eval()\n",
    "model_1.cuda()\n",
    "\n",
    "def get_tokens_and_labels_indices_from_text(text):\n",
    "    # MODEL 0\n",
    "    tokenized_sentence = tokenizer.encode(text)\n",
    "    input_ids = torch.tensor([tokenized_sentence]).cuda()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "    label_indices = output[0].to('cpu').numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "    # MODEL 1\n",
    "    tokenized_sentence_1 = tokenizer_1.encode(text)\n",
    "    input_ids_1 = torch.tensor([tokenized_sentence_1]).cuda()\n",
    "    with torch.no_grad():\n",
    "        output_1 = model_1(input_ids_1)\n",
    "    label_indices_1 = output_1[0].to('cpu').numpy()\n",
    "    tokens_1 = tokenizer_1.convert_ids_to_tokens(input_ids_1.to('cpu').numpy()[0])\n",
    "    return tokens, label_indices, tokens_1, label_indices_1\n",
    "\n",
    "def map_tokens_and_labels_to_word_and_punctuations(text):\n",
    "    if len(text) > 2048:\n",
    "        full_text = \" \".join(text.split())\n",
    "        if full_text[-1] not in [\"।\", \"!\", \"?\", \"-\"]:\n",
    "            full_text += \"।\"\n",
    "        return full_text\n",
    "    tokens, label_indices, tokens_1, label_indices_1 = get_tokens_and_labels_indices_from_text(text)\n",
    "    new_tokens = []\n",
    "    new_labels = []\n",
    "    for i in range(1, len(tokens) - 1):\n",
    "        if tokens[i].startswith(\"▁\"):\n",
    "            current_word = tokens[i][1:]\n",
    "            new_labels.append(label_indices[0][i])\n",
    "            for j in range(i + 1, len(tokens) - 1):\n",
    "                if not tokens[j].startswith(\"▁\"):\n",
    "                    current_word = current_word + tokens[j]\n",
    "                if tokens[j].startswith(\"▁\"):\n",
    "                    break\n",
    "            new_tokens.append(current_word)\n",
    "    full_text = ''\n",
    "    tokenized_text = indic_tokenize.trivial_tokenize_indic(text)\n",
    "    \n",
    "    if len(tokenized_text) == len(new_labels):\n",
    "        full_text_tokens = tokenized_text\n",
    "    else:\n",
    "        full_text_tokens = new_tokens\n",
    "    new_tokens_1 = []\n",
    "    new_labels_1 = []\n",
    "    for i in range(1, len(tokens_1) - 1):\n",
    "        if tokens_1[i].startswith(\"▁\"):\n",
    "            current_word_1 = tokens_1[i][1:]\n",
    "            new_labels_1.append(label_indices_1[0][i])\n",
    "            for j in range(i + 1, len(tokens_1) - 1):\n",
    "                if not tokens_1[j].startswith(\"▁\"):\n",
    "                    current_word_1 = current_word_1 + tokens_1[j]\n",
    "                if tokens_1[j].startswith(\"▁\"):\n",
    "                    break\n",
    "            new_tokens_1.append(current_word_1)\n",
    "    if len(new_labels) == len(new_labels_1):\n",
    "        for word, punctuation_0, punctuation_1 in zip(full_text_tokens, new_labels, new_labels_1):\n",
    "            x_0 = np.exp(punctuation_0 - np.max(punctuation_0))\n",
    "            pred_0 = x_0 / np.sum(x_0)\n",
    "            x_1 = np.exp(punctuation_1 - np.max(punctuation_1))\n",
    "            pred_1 = x_1 / np.sum(x_1)\n",
    "            punctuation = pred_0 * 0.95 + pred_1 * 0.05\n",
    "            punctuation = np.argmax(punctuation)\n",
    "            punctuation = list(train_encoder.keys())[list(train_encoder.values()).index(punctuation)]\n",
    "            full_text = full_text + word + punctuation_dict[punctuation]\n",
    "    else:\n",
    "        for word, punctuation in zip(full_text_tokens, new_labels):\n",
    "            punctuation = np.argmax(punctuation)\n",
    "            punctuation = list(train_encoder.keys())[list(train_encoder.values()).index(punctuation)]\n",
    "            full_text = full_text + word + punctuation_dict[punctuation]\n",
    "    \n",
    "    full_text = \" \".join(full_text.split())\n",
    "    if len(full_text) == 0:\n",
    "        full_text = \" \".join(text.split())\n",
    "        if len(full_text) == 0:\n",
    "            full_text = \"।\"\n",
    "    if full_text[-1] in [\",\", \"-\"]:\n",
    "        full_text = full_text[:-1] + \"।\"\n",
    "    if full_text[-1] not in [\"।\", \"!\", \"?\"]:\n",
    "        full_text += \"।\"\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "sub = pd.read_csv(\"pre_submission.csv\")\n",
    "sub['sentence'] = sub['sentence'].apply(map_tokens_and_labels_to_word_and_punctuations)\n",
    "\n",
    "from bnunicodenormalizer import Normalizer\n",
    "bnorm = Normalizer()\n",
    "def normalize(sentence):\n",
    "    word = [bnorm(word)['normalized'] for word in sentence.split()]\n",
    "    return \" \".join([w for w in word if w is not None])\n",
    "sub['sentence'] = sub['sentence'].apply(lambda x: normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b7ead6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:44:13.411494Z",
     "iopub.status.busy": "2023-10-19T06:44:13.411232Z",
     "iopub.status.idle": "2023-10-19T06:44:14.557311Z",
     "shell.execute_reply": "2023-10-19T06:44:14.556398Z"
    },
    "papermill": {
     "duration": 1.159998,
     "end_time": "2023-10-19T06:44:14.559317",
     "exception": false,
     "start_time": "2023-10-19T06:44:13.399319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7309f1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T06:44:14.583216Z",
     "iopub.status.busy": "2023-10-19T06:44:14.582937Z",
     "iopub.status.idle": "2023-10-19T06:44:14.590504Z",
     "shell.execute_reply": "2023-10-19T06:44:14.589913Z"
    },
    "papermill": {
     "duration": 0.021301,
     "end_time": "2023-10-19T06:44:14.592016",
     "exception": false,
     "start_time": "2023-10-19T06:44:14.570715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1127.931855,
   "end_time": "2023-10-19T06:44:18.114954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-19T06:25:30.183099",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
