{"cells":[{"cell_type":"markdown","source":["# Step 1. Preparing Dataset\n","In this notebook, we will clean Bengali sentences. Please prepare train.csv (given data) with fold column in advance. In this notebook, \"train_with_fold.csv\" is the file."],"metadata":{"id":"8zDj--5lhcdn"}},{"cell_type":"markdown","metadata":{"id":"20j3Yatfg9yo"},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"rIf3DgJng9yw"},"outputs":[],"source":["!pip install joblib\n","!pip install indic-nlp-library\n","!pip install bnunicodenormalizer\n","!wget -P . https://objectstore.e2enetworks.net/ai4b-public-nlu-nlg/indic-corp-frozen-for-the-paper-oct-2022/bn.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"kvmOLHKrg9yy"},"outputs":[],"source":["import re\n","import argparse\n","import pandas as pd\n","from tqdm import tqdm\n","from joblib import Parallel, delayed\n","from bnunicodenormalizer import Normalizer\n","from indicnlp.tokenize.indic_tokenize import trivial_tokenize"]},{"cell_type":"markdown","metadata":{"id":"Jj5N9Zeng9yy"},"source":["# Process Raw Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"he_qs6_og9yz"},"outputs":[],"source":["def make_pattern_from_dict():\n","    pattern = '[^\\u0980-\\u09FF\\ \\,\\।\\?\\-]'\n","    return pattern\n","\n","def find_punctuation_count(line):\n","    sent = []\n","    sent.append(line)\n","    punc = re.findall('[\\,\\।\\?\\-]+', line)\n","    return sent + [punc.count(ch) for ch in [',', '।', '?', '-']]\n","\n","def process_sent(sent):\n","    normalized = normalize(sent)\n","    processed = ' '.join(trivial_tokenize(normalized, 'bn'))\n","    return processed\n","\n","def filter_line(line):\n","    out = None\n","    if re.search(punc, line):\n","        line = process_sent(line.strip())\n","        clean_line = re.sub(pattern, ' ', line)\n","        if not (clean_line and (clean_line[0] in [',', '।', '?', '-'])):\n","            temp_line = clean_line.replace(\" \",\"\")\n","            if not regex.search(temp_line):\n","                out =  ' '.join(clean_line.split())\n","    return out\n","\n","def get_clean_data():\n","    global pattern, punc, regex, normalize\n","\n","    punc = '[\\,\\।\\?\\-]+'\n","    regex = re.compile('[\\,\\।\\?\\-]{2,}')\n","    bnorm = Normalizer()\n","    def normalize(sentence):\n","        word = [bnorm(word)['normalized'] for word in sentence.split()]\n","        return \" \".join([w for w in word if w is not None])\n","    pattern = make_pattern_from_dict()\n","\n","    print(\"--------------------------------Processing (given train)----------------------------------\")\n","    given_df = pd.read_csv('train_with_fold.csv', usecols=['sentence', 'fold'])\n","    given_df = given_df[given_df['fold'] != 0].reset_index(drop=True)\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('!', '।', x))\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('[\\।\\?]*\\?[\\।\\?]*', '?', x))\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('।+', '।', x))\n","    line_list = given_df['sentence'].tolist()\n","\n","    outfile = open('processed_given_train.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (given valid)----------------------------------\")\n","    given_df = pd.read_csv('train_with_fold.csv', usecols=['sentence', 'fold'])\n","    given_df = given_df[given_df['fold'] == 0].reset_index(drop=True)\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('!', '।', x))\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('[\\।\\?]*\\?[\\।\\?]*', '?', x))\n","    given_df['sentence'] = given_df['sentence'].apply(lambda x: re.sub('।+', '।', x))\n","    line_list = given_df['sentence'].tolist()\n","\n","    outfile = open('processed_given_valid.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 1/4----------------------------------\")\n","    line_list = []\n","    with open(\"bn.txt\") as inpfile:\n","        line_list.extend(inpfile.readlines()[:10000000])\n","        print(len(line_list))\n","\n","    outfile = open('processed_indiccorpv2_0.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 2/4----------------------------------\")\n","    line_list = []\n","    with open(\"bn.txt\") as inpfile:\n","        line_list.extend(inpfile.readlines()[10000000:20000000])\n","        print(len(line_list))\n","\n","    outfile = open('processed_indiccorpv2_1.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 3/4----------------------------------\")\n","    line_list = []\n","    with open(\"bn.txt\") as inpfile:\n","        line_list.extend(inpfile.readlines()[20000000:30000000])\n","        print(len(line_list))\n","\n","    outfile = open('processed_indiccorpv2_2.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 4/4----------------------------------\")\n","    line_list = []\n","    with open(\"bn.txt\") as inpfile:\n","        line_list.extend(inpfile.readlines()[30000000:])\n","        print(len(line_list))\n","\n","    outfile = open('processed_indiccorpv2_3.tsv', 'w')\n","    print(\"sentence\\tcomma_count\\tend_count\\tqm_count\\thyp_count\", file=outfile)\n","\n","    gen = (filter_line(line) for line in line_list)\n","\n","    out = Parallel(n_jobs=-1)(delayed(find_punctuation_count)(line) for line in tqdm(gen) if line)\n","\n","    for line in tqdm(out):\n","        print(*line, sep=\"\\t\", file=outfile)\n","\n","    outfile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOt_Kimeg9y1","outputId":"3bfe640e-a6f5-4afd-dda2-f4a380ce1e37"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------Processing (IndicCorp v2) 4/4----------------------------------\n","11004792\n"]},{"name":"stderr","output_type":"stream","text":["2568264it [3:30:34, 170.93it/s]"]}],"source":["get_clean_data()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}