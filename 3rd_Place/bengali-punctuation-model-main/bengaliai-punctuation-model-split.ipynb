{"cells":[{"cell_type":"markdown","source":["# Step 2. Splitting Dataset\n","This notebook formats Bengali sentences into training data."],"metadata":{"id":"h9uk5RSsit8y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUYC5trVihOG"},"outputs":[],"source":["import os\n","import pandas as pd\n","from tqdm import tqdm\n","from joblib import Parallel, delayed\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4r8MiUjvihOI"},"outputs":[],"source":["def fix_for_first_ch_punc(line):\n","    if line and (line[0] in [',', 'ред', '?', '-']):\n","        line = line[1:]\n","        return ' '.join(line.split())\n","    return line\n","\n","def split_sen_with_label(line):\n","    line = fix_for_first_ch_punc(line)\n","    words, labels = [], []\n","    word_list = line.split()\n","    for w in word_list:\n","        if w in [',', 'ред', '?', '-']:\n","            if w == ',':\n","                lab = 'comma'\n","            elif w == 'ред':\n","                lab = 'end'\n","            elif w == '?':\n","                lab = 'qm'\n","            elif w == '-':\n","                lab = 'hyp'\n","            labels.pop()\n","            labels.append(lab)\n","        else:\n","            lab = 'blank'\n","            words.append(w)\n","            labels.append(lab)\n","\n","    yield words, labels\n","\n","def transform_data():\n","    print(\"--------------------------------Processing (given train)----------------------------------\")\n","    df = pd.read_csv('processed_given_train.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","\n","    line_list = df['sentence'].tolist()\n","\n","    outfile = open('given_train.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (given valid)----------------------------------\")\n","    df = pd.read_csv('processed_given_valid.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","\n","    line_list = df['sentence'].tolist()\n","\n","    outfile = open('given_valid.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 1/4----------------------------------\")\n","    df = pd.read_csv('processed_indiccorpv2_0.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","    df_train, df_valid = train_test_split(df, test_size=0.01, random_state=42)\n","\n","    line_list = df_train['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_0_train.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    line_list = df_valid['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_0_valid.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 2/4----------------------------------\")\n","    df = pd.read_csv('processed_indiccorpv2_1.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","    df_train, df_valid = train_test_split(df, test_size=0.01, random_state=42)\n","\n","    line_list = df_train['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_1_train.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    line_list = df_valid['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_1_valid.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 3/4----------------------------------\")\n","    df = pd.read_csv('processed_indiccorpv2_2.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","    df_train, df_valid = train_test_split(df, test_size=0.01, random_state=42)\n","\n","    line_list = df_train['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_2_train.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    line_list = df_valid['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_2_valid.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    print(\"--------------------------------Processing (IndicCorp v2) 4/4----------------------------------\")\n","    df = pd.read_csv('processed_indiccorpv2_3.tsv', sep='\\t')\n","    print(\"Before CSV length:\", len(df))\n","    df = df.drop_duplicates().reset_index(drop=True)\n","    print(\"After CSV length:\", len(df))\n","    df_train, df_valid = train_test_split(df, test_size=0.01, random_state=42)\n","\n","    line_list = df_train['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_3_train.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    def process(ix, line):\n","        g = split_sen_with_label(line)\n","        words, labels = next(g)\n","        if len(words) == len(labels):\n","            return [ix+1,\" \".join(words),\" \".join(labels)]\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()\n","\n","    line_list = df_valid['sentence'].tolist()\n","\n","    outfile = open('indiccorpv2_3_valid.csv', 'w')\n","    print('sentence_index,sentence,label', file=outfile)\n","\n","    out = Parallel(n_jobs=-1)(delayed(process)(ix, line) for ix, line in tqdm(enumerate(line_list)))\n","\n","    for i in tqdm(out):\n","        print(*i, sep=',', file=outfile)\n","\n","    outfile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSlYzgz9ihON"},"outputs":[],"source":["transform_data()"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}